# -------------------------------------------------------------------------------------- #
# Cervical Cancer Screening
# -------------------------------------------------------------------------------------- #

import time
import numpy as np
import skimage.io as io
import keras
from keras.models import Sequential
from keras.utils import np_utils
from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D
from keras.wrappers.scikit_learn import KerasClassifier
from sklearn.model_selection import cross_val_score
from sklearn.model_selection import train_test_split

#%%
# -------------------------------------------------------------------------------------- #
# Creation of training and test datasets

rootDir = "C:/Users/rarez/Documents/Data Science/cervical_cancer/data_work/Cropped_200x200/train"

sourcePath = rootDir + "/Type_1/*.jpg"
imgColl = io.imread_collection(sourcePath)
X_1 = io.concatenate_images(imgColl)
y_1 = 0*np.ones(X_1.shape[0], dtype=int)

sourcePath = rootDir + "/Type_2/*.jpg"
imgColl = io.imread_collection(sourcePath)
X_2 = io.concatenate_images(imgColl)
y_2 = 1*np.ones(X_2.shape[0], dtype=int)

sourcePath = rootDir + "/Type_3/*.jpg"
imgColl = io.imread_collection(sourcePath)
X_3 = io.concatenate_images(imgColl)
y_3 = 2*np.ones(X_3.shape[0], dtype=int)

X_all = np.concatenate([X_1, X_2, X_3])
X_all = X_all.astype('float32')
X_all /= 255
y_all = np.concatenate([y_1, y_2, y_3])
y_all = np_utils.to_categorical(y_all)

#X_train = X_all
#y_train = y_all

X_train, X_test, y_train, y_test = train_test_split(X_all, y_all, test_size=0.15, random_state=31416)


#%%
# -------------------------------------------------------------------------------------- #
# Definition of Convolutional Neural Network

def create_model():
    cnn = Sequential()
    cnn.add(Conv2D(32, (3, 3), padding="same", activation="relu", input_shape=X_train.shape[1:]))
    cnn.add(Conv2D(32, (3, 3), padding="same", activation="relu"))
    cnn.add(MaxPooling2D(pool_size=(2,2)))
    cnn.add(Dropout(0.25))


    cnn.add(Conv2D(64, (3, 3), padding="same", activation="relu"))
    cnn.add(Conv2D(64, (3, 3), padding="same", activation="relu"))
    cnn.add(MaxPooling2D(pool_size=(2,2)))
    cnn.add(Dropout(0.25))
    
    cnn.add(Conv2D(128, (3, 3), padding="same", activation="relu"))
    cnn.add(Conv2D(128, (3, 3), padding="same", activation="relu"))
    cnn.add(Conv2D(128, (3, 3), padding="same", activation="relu"))
    cnn.add(MaxPooling2D(pool_size=(2,2)))
    cnn.add(Dropout(0.25))
    
    cnn.add(Flatten())
    cnn.add(Dense(512, activation="relu"))
    cnn.add(Dropout(0.5))
    cnn.add(Dense(3, activation="softmax"))
    
    #opt = keras.optimizers.rmsprop(lr=0.0001, decay=1e-6)
    opt = keras.optimizers.rmsprop(lr=0.000025, decay=1e-6)

    cnn.compile(loss="categorical_crossentropy", optimizer=opt, metrics=['accuracy'])
    
    return cnn

#%%
# -------------------------------------------------------------------------------------- #
# Training with data augmentation

from keras.preprocessing.image import ImageDataGenerator

startTime = time.time()

batch_size = 32
#epochs = 130
epochs = 120

datagen = ImageDataGenerator(
    featurewise_center=False,               # set input mean to 0 over the dataset
    samplewise_center=False,                # set each sample mean to 0
    featurewise_std_normalization=False,    # divide inputs by std of the dataset
    samplewise_std_normalization=False,     # divide each input by its std
    zca_whitening=False,                    # apply ZCA whitening
    rotation_range=0,                       # randomly rotate images in the range (degrees, 0 to 180)
    width_shift_range=0.1,                  # randomly shift images horizontally (fraction of total width)
    height_shift_range=0.1,                 # randomly shift images vertically (fraction of total height)
    horizontal_flip=True,                   # randomly flip images
    vertical_flip=False)                    # randomly flip images

# Compute quantities required for feature-wise normalization
# (std, mean, and principal components if ZCA whitening is applied).
datagen.fit(X_train)

classifier = create_model()

# Fit the model on the batches generated by datagen.flow().
classifier.fit_generator(datagen.flow(X_train, y_train, batch_size=batch_size),
                         steps_per_epoch=X_train.shape[0] // batch_size,
                         epochs=epochs,
                         validation_data=(X_test, y_test))

print("Total processing time: {:.2f} minutes".format((time.time()-startTime)/60))



#%%
# -------------------------------------------------------------------------------------- #
# Training without data augmentation

startTime = time.time()

batch_size = 32
epochs = 50

classifier = create_model()

classifier.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, y_test))

print("Total processing time: {:.2f} minutes".format((time.time()-startTime)/60))


#%%
# -------------------------------------------------------------------------------------- #
# Submission

import pandas as pd

rootDir = "C:/Users/rarez/Documents/Data Science/cervical_cancer/"

sourcePath = rootDir + "data_work/Cropped_200x200/test/*.jpg"

nameTrailer = 'C:/Users/rarez/Documents/Data Science/cervical_cancer/data_work/Cropped_200x200/test\\'

imgColl = io.imread_collection(sourcePath)
X_test = io.concatenate_images(imgColl)
X_test = X_test.astype('float32')
X_test /= 255

y_test = classifier.predict_proba(X_test)

subFiles =[]
fileNames = imgColl.files
for fileName in fileNames:
    subFiles.append(str(fileName).replace(nameTrailer, ''))

dfFileNames = pd.DataFrame({'image_name': subFiles})
dfProbs = pd.DataFrame({'Type_1': y_test[:,0], 'Type_2': y_test[:,1], 'Type_3': y_test[:,2]})
submission = pd.concat((dfFileNames, dfProbs), 1)

submission.to_csv(rootDir + "submission.csv", index = False)

    

#%%

startTime = time.time()

classifier = KerasClassifier(build_fn = create_model, epochs=15, batch_size=32, verbose=True)

classifier.fit(X_train, y_train)

scores = cross_val_score(classifier, X_train, y_train, cv=5, scoring = "neg_log_loss")

print("LogLoss: {:.3f} (+/- {:.3f})".format(scores.mean(), scores.std()))

print("Total processing time: {:.2f} minutes".format((time.time()-startTime)/60))

































